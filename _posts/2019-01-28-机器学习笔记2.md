### 1. $L_1$ & $ L_2 $正则化是一种常用的减少过拟合的方法

  - 目的：减少过拟合
  - 资料来源：<https://developers.google.com/machine-learning/crash-course/regularization-for-sparsity/l1-regularization>





### 2. Colab的代码实际上是运行在google免费提供的虚拟机上的

### 获取信息的一些方法

- 可以用下面的一些方式来查看信息，硬盘空间128G

![image-20190129225800368](https://ws3.sinaimg.cn/large/006tNc79gy1fznuklossyj312d07y3zz.jpg)

- 内存容量 10多G，CPU是双核xeon

![image-20190129230226068](https://ws4.sinaimg.cn/large/006tNc79gy1fznup73b0nj30gh05hwf0.jpg)

- 来源：<https://www.jianshu.com/p/81eae79ee78b>



### 3. Model.compile

参考资料：<https://keras-cn.readthedocs.io/en/latest/models/model/>

在这里有几个参数

##### 3.1 optimizer

- 资料来源：<https://keras-cn.readthedocs.io/en/latest/other/optimizers/>
- SGD （很常用）
- RMSprop
- Adagrad （见过）

##### 3.2 loss

- 资料来源：<https://keras-cn.readthedocs.io/en/latest/other/objectives/>
- mse
- mae
- mape
- msle
- binary_crossentropy
- categorical_crossentropy

##### 3.3 metrics

- 典型用法是metrics=['accuracy']